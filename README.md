# ğŸ¦ Plataforma de AnÃ¡lisis de Riesgo Crediticio

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104%2B-green)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28%2B-red)
![Docker](https://img.shields.io/badge/Docker-20.10%2B-2496ED)
![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-âœ”-2088FF)

Sistema completo para anÃ¡lisis y predicciÃ³n de riesgo crediticio usando Machine Learning, con API REST, Dashboard interactivo y pipeline CI/CD automatizado.

## âœ¨ CaracterÃ­sticas Principales

### ğŸ¯ **Machine Learning**
- **GeneraciÃ³n de datos sintÃ©ticos** realistas para pruebas
- **Pipeline ETL** completo y reproducible
- **Feature engineering** avanzado con dominio financiero
- **MÃºltiples algoritmos**: Random Forest, Gradient Boosting, Logistic Regression
- **ValidaciÃ³n cruzada** y ajuste de hiperparÃ¡metros
- **MÃ©tricas completas**: ROC AUC, precisiÃ³n, recall, F1-score

### ğŸš€ **API REST con FastAPI**
- **DocumentaciÃ³n automÃ¡tica** (Swagger/OpenAPI)
- **AutenticaciÃ³n** con tokens JWT
- **Predicciones individuales** y **por lotes**
- **Health checks** y monitoreo
- **Rate limiting** y manejo de errores
- **Caching** con Redis

### ğŸ“Š **Dashboard Interactivo**
- **Visualizaciones en tiempo real** con Plotly
- **Formularios interactivos** para predicciones
- **Carga de archivos CSV** para procesamiento por lotes
- **AnÃ¡lisis exploratorio** integrado
- **SegmentaciÃ³n** por variables demogrÃ¡ficas
- **GeneraciÃ³n de reportes** automÃ¡ticos

### ğŸ³ **Infraestructura Moderna**
- **DockerizaciÃ³n completa** con multi-stage builds
- **OrquestaciÃ³n** con Docker Compose
- **CI/CD automÃ¡tico** con GitHub Actions
- **Base de datos PostgreSQL** para producciÃ³n
- **Redis** para caching y colas
- **Nginx** como reverse proxy

## ğŸš€ Comenzando

### Prerrequisitos
- **Python 3.10+**
- **Docker 20.10+** (opcional, recomendado)
- **Docker Compose 2.0+** (opcional)
- **Git**

### InstalaciÃ³n RÃ¡pida

#### MÃ©todo 1: Docker (Recomendado)

```bash
# 1. Clonar el repositorio
git clone https://github.com/tu-usuario/credito-risk-platform.git
cd credito-risk-platform

# 2. Iniciar todos los servicios
make docker-up

# 3. Verificar que todo funciona
curl http://localhost:8000/health

# 4. Abrir el dashboard
# Navegador: http://localhost:8501
```

#### MÃ©todo 2: Desarrollo Local

```bash
# 1. Clonar el repositorio
git clone https://github.com/tu-usuario/credito-risk-platform.git
cd credito-risk-platform

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. Instalar dependencias
make install

# 4. Generar datos y entrenar modelo
make generate-data
make train-model

# 5. Iniciar servicios (en terminales separadas)
make run-api      # Terminal 1 - API en http://localhost:8000
make run-dashboard # Terminal 2 - Dashboard en http://localhost:8501
```

## ğŸ“ Estructura del Proyecto

```
credito-risk-platform/
â”œâ”€â”€ src/                    # CÃ³digo fuente
â”‚   â”œâ”€â”€ api/               # API REST con FastAPI
â”‚   â”‚   â”œâ”€â”€ app.py         # AplicaciÃ³n principal
â”‚   â”‚   â”œâ”€â”€ schemas.py     # Esquemas Pydantic
â”‚   â”‚   â”œâ”€â”€ config.py      # ConfiguraciÃ³n
â”‚   â”‚   â””â”€â”€ dependencies.py # Dependencias e inyecciÃ³n
â”‚   â”œâ”€â”€ dashboard/         # Dashboard con Streamlit
â”‚   â”‚   â”œâ”€â”€ app.py         # AplicaciÃ³n principal
â”‚   â”‚   â””â”€â”€ config.py      # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ etl/              # Pipeline ETL
â”‚   â”‚   â””â”€â”€ pipeline.py    # ExtracciÃ³n, transformaciÃ³n, carga
â”‚   â”œâ”€â”€ features/          # Feature engineering
â”‚   â”‚   â””â”€â”€ feature_engineering.py # IngenierÃ­a de caracterÃ­sticas
â”‚   â”œâ”€â”€ models/           # Modelos de Machine Learning
â”‚   â”‚   â””â”€â”€ train_model.py # Entrenamiento y predicciÃ³n
â”‚   â”œâ”€â”€ validation/       # ValidaciÃ³n de modelos
â”‚   â”‚   â””â”€â”€ model_validator.py # ValidaciÃ³n y monitoreo
â”‚   â””â”€â”€ utils/            # Utilidades
â”‚       â””â”€â”€ data_generator.py # Generador de datos sintÃ©ticos
â”œâ”€â”€ docker/               # ConfiguraciÃ³n Docker
â”‚   â”œâ”€â”€ Dockerfile.api    # Imagen para API
â”‚   â”œâ”€â”€ Dockerfile.dashboard # Imagen para Dashboard
â”‚   â”œâ”€â”€ Dockerfile.train  # Imagen para entrenamiento
â”‚   â”œâ”€â”€ docker-compose.yml # OrquestaciÃ³n
â”‚   â””â”€â”€ nginx/            # ConfiguraciÃ³n Nginx
â”‚       â””â”€â”€ nginx.conf
â”œâ”€â”€ tests/               # Tests unitarios e integraciÃ³n
â”‚   â”œâ”€â”€ test_api.py      # Tests para API
â”‚   â”œâ”€â”€ test_dashboard.py # Tests para Dashboard
â”‚   â”œâ”€â”€ test_features.py  # Tests para feature engineering
â”‚   â”œâ”€â”€ test_models.py   # Tests para modelos ML
â”‚   â”œâ”€â”€ test_generator.py # Tests para generador
â”‚   â””â”€â”€ test_pipeline.py # Tests para pipeline ETL
â”œâ”€â”€ scripts/             # Scripts utilitarios
â”‚   â”œâ”€â”€ entrypoint.sh    # Script de entrada
â”‚   â”œâ”€â”€ wait-for-it.sh   # Espera por servicios
â”‚   â””â”€â”€ healthcheck.sh   # Health checks
â”œâ”€â”€ data/                # Datos (gitignored)
â”‚   â”œâ”€â”€ raw/            # Datos crudos
â”‚   â”œâ”€â”€ processed/      # Datos procesados
â”‚   â””â”€â”€ features/       # Features para ML
â”œâ”€â”€ models/             # Modelos entrenados (gitignored)
â”œâ”€â”€ notebooks/          # Jupyter notebooks para anÃ¡lisis
â”‚   â””â”€â”€ exploratory_analysis.ipynb
â”œâ”€â”€ .github/            # GitHub Actions CI/CD
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml      # IntegraciÃ³n continua
â”‚       â”œâ”€â”€ cd.yml      # Despliegue continuo
â”‚       â””â”€â”€ train-model.yml # Entrenamiento automÃ¡tico
â”œâ”€â”€ docs/               # DocumentaciÃ³n adicional
â”œâ”€â”€ requirements/       # Dependencias organizadas
â”‚   â”œâ”€â”€ api.txt        # Dependencias API
â”‚   â”œâ”€â”€ dashboard.txt  # Dependencias Dashboard
â”‚   â””â”€â”€ dev.txt        # Dependencias desarrollo
â”œâ”€â”€ Makefile           # Comandos automatizados
â”œâ”€â”€ main.py            # Punto de entrada principal
â””â”€â”€ README.md          # Este archivo
```

## ğŸ³ Docker

### Servicios Disponibles

| Servicio | Puerto | DescripciÃ³n | URL |
|----------|--------|-------------|-----|
| **API** | 8000 | API REST FastAPI | http://localhost:8000 |
| **Dashboard** | 8501 | Dashboard Streamlit | http://localhost:8501 |
| **PostgreSQL** | 5432 | Base de datos | localhost:5432 |
| **Redis** | 6379 | Cache y colas | localhost:6379 |
| **Nginx** | 80 | Reverse proxy | http://localhost |

### Comandos Docker

```bash
# Construir todas las imÃ¡genes
make docker-build

# Iniciar todos los servicios (en background)
make docker-up

# Ver logs en tiempo real
make docker-logs

# Detener todos los servicios
make docker-down

# Entrenar modelo en contenedor
make docker-train

# Acceder a shell del contenedor API
make docker-shell

# Ver estado de los servicios
docker-compose ps

# Reconstruir y reiniciar un servicio especÃ­fico
docker-compose up -d --build api
```

### ConfiguraciÃ³n de Variables de Entorno

Crea un archivo `.env` en la raÃ­z del proyecto:

```env
# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false
API_AUTH_TOKEN=your-secure-token-here
SECRET_KEY=your-secret-key-change-in-production
ALGORITHM=HS256

# Database
DATABASE_URL=postgresql://credit_user:credit_password@postgres:5432/credit_db

# Redis
REDIS_URL=redis://redis:6379/0

# Model
MODEL_PATH=models/random_forest_model_latest.pkl
MODEL_METADATA_PATH=models/random_forest_model_latest_metadata.json

# Dashboard
DASHBOARD_PORT=8501
API_URL=http://api:8000  # Interno para Docker
```

## ğŸ”§ Desarrollo

### InstalaciÃ³n para Desarrollo

```bash
# Clonar y configurar
git clone https://github.com/tu-usuario/credito-risk-platform.git
cd credito-risk-platform

# Instalar dependencias completas
make install

# Ejecutar pipeline completo
python main.py todo --clientes 1000

# Ejecutar tests
make test

# Verificar calidad de cÃ³digo
make lint

# Formatear cÃ³digo automÃ¡ticamente
make format
```

### Comandos Principales

```bash
# Pipeline completo (datos + features + modelo)
python main.py todo --clientes 5000

# Solo generaciÃ³n de datos
python main.py fase1 --clientes 1000

# Solo feature engineering
python main.py fase2-features

# Solo entrenamiento de modelo
python main.py fase2-train --model-type random_forest --tune-hyperparams

# Solo validaciÃ³n
python main.py fase2-validate

# Iniciar solo API
python run.py api

# Iniciar solo Dashboard
python run.py dashboard
```

### Tests

```bash
# Ejecutar todos los tests
pytest tests/ -v

# Ejecutar tests con cobertura
pytest tests/ --cov=src --cov-report=html

# Tests especÃ­ficos
pytest tests/test_api.py -v
pytest tests/test_models.py -v

# Tests con mayor detalle
pytest tests/ -v --tb=short
```

## ğŸ“Š Uso del Sistema

### API REST

La API estÃ¡ disponible en `http://localhost:8000`.

#### Endpoints Principales

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| `GET` | `/` | Health check bÃ¡sico |
| `GET` | `/health` | Health check detallado |
| `GET` | `/model/info` | InformaciÃ³n del modelo cargado |
| `GET` | `/features` | Lista de features esperadas |
| `POST` | `/predict` | PredicciÃ³n individual |
| `POST` | `/predict/batch` | PredicciÃ³n por lotes |

#### Ejemplo de PredicciÃ³n

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Authorization: Bearer your-token" \
  -H "Content-Type: application/json" \
  -d '{
    "edad": 35,
    "genero": "M",
    "estado_civil": "casado",
    "dependientes": 1,
    "ingreso_mensual": 3000.0,
    "gastos_mensuales": 2000.0,
    "total_adeudado": 5000.0,
    "ahorros": 10000.0,
    "score_bancario": 720,
    "antiguedad_empleo": 24,
    "tipo_contrato": "indefinido",
    "num_creditos_previos": 2,
    "max_dias_mora": 15,
    "creditos_problematicos": 0,
    "tipo_vivienda": "propia",
    "antiguedad_residencia": 5
  }'
```

#### Respuesta de Ejemplo

```json
{
  "prediction": 0,
  "probability_default": 0.1234,
  "risk_score": 785,
  "risk_category": "EXCELENTE",
  "features_used": ["edad", "ingreso_mensual", ...],
  "message": "PredicciÃ³n completada exitosamente"
}
```

### Dashboard

Disponible en `http://localhost:8501`

#### Funcionalidades del Dashboard

1. **ğŸ“ˆ VisiÃ³n General**
   - KPIs del sistema
   - DistribuciÃ³n de edades e ingresos
   - Mapa de calor de correlaciones

2. **ğŸ¯ Predicciones**
   - Formulario interactivo para predicciones individuales
   - Carga de archivos CSV para predicciones por lotes
   - VisualizaciÃ³n de resultados con grÃ¡ficos

3. **ğŸ“Š AnÃ¡lisis**
   - SegmentaciÃ³n por variables demogrÃ¡ficas
   - DetecciÃ³n de patrones y correlaciones
   - GeneraciÃ³n de reportes automÃ¡ticos

4. **âš™ï¸ ConfiguraciÃ³n**
   - Ajuste de parÃ¡metros del sistema
   - ConfiguraciÃ³n de conexiones API

## ğŸ¤– Machine Learning

### CaracterÃ­sticas del Modelo

#### Features Generadas

| CategorÃ­a | Ejemplos de Features |
|-----------|---------------------|
| **DemogrÃ¡ficas** | Edad, gÃ©nero, estado civil, dependientes |
| **Financieras** | Ingreso mensual, gastos, ahorros, deuda total |
| **Laborales** | AntigÃ¼edad empleo, tipo contrato, estabilidad |
| **Crediticias** | Historial de crÃ©ditos, dÃ­as de mora, score bancario |
| **Calculadas** | Ratio deuda/ingreso, capacidad de pago, score compuesto |

#### Algoritmos Disponibles

1. **Random Forest** (por defecto)
   - Robustez a outliers
   - Feature importance automÃ¡tica
   - Buen performance con datos no lineales

2. **Gradient Boosting**
   - Alta precisiÃ³n
   - Manejo de relaciones complejas
   - Requiere mÃ¡s ajuste de hiperparÃ¡metros

3. **Logistic Regression**
   - Interpretabilidad
   - Rapidez de entrenamiento
   - Baseline para comparaciÃ³n

#### MÃ©tricas de EvaluaciÃ³n

- **Accuracy**: Exactitud general
- **Precision**: Exactitud en predicciones positivas
- **Recall**: Sensibilidad para detectar defaults
- **F1-Score**: Balance entre precisiÃ³n y recall
- **ROC AUC**: Capacidad discriminativa del modelo
- **Confusion Matrix**: VisualizaciÃ³n de errores

### Pipeline de Entrenamiento

```python
# Ejemplo de entrenamiento programÃ¡tico
from src.models.train_model import CreditRiskModel
import pandas as pd

# Cargar datos
df = pd.read_parquet('data/features/features_engineered.parquet')

# Inicializar modelo
model = CreditRiskModel(model_type='random_forest')

# Preparar datos (train/test split)
X_train, X_test, y_train, y_test = model.prepare_data(df)

# Entrenar con cross-validation
model.train(X_train, y_train, use_cv=True)

# Evaluar en test
model.evaluate(X_test, y_test)

# Guardar modelo
model.save_model('models/')
```

## ğŸ”„ CI/CD Pipeline

### GitHub Actions Workflows

#### 1. **CI (Continuous Integration)**
- Ejecuta en cada push y pull request
- Tests unitarios con pytest
- Linting con flake8 y black
- Type checking con mypy
- Build de imÃ¡genes Docker

#### 2. **CD (Continuous Deployment)**
- Ejecuta en releases y manualmente
- Despliegue automÃ¡tico a servidor
- Migraciones de base de datos
- Health checks post-deployment
- Notificaciones a Slack

#### 3. **Entrenamiento de Modelos**
- EjecuciÃ³n programada (semanal)
- Descarga de datos actualizados
- Entrenamiento de nuevo modelo
- Upload a almacenamiento en la nube
- Notificaciones de actualizaciÃ³n

### ConfiguraciÃ³n de Secrets

Para que CI/CD funcione, configura estos secrets en GitHub:

| Secret | DescripciÃ³n |
|--------|-------------|
| `DOCKER_USERNAME` | Usuario de Docker Hub |
| `DOCKER_PASSWORD` | ContraseÃ±a de Docker Hub |
| `SSH_PRIVATE_KEY` | Clave SSH para despliegue |
| `SERVER_HOST` | Host del servidor de producciÃ³n |
| `SERVER_USER` | Usuario del servidor |
| `PRODUCTION_DATABASE_URL` | URL de base de datos producciÃ³n |
| `SLACK_WEBHOOK_URL` | Webhook para notificaciones |

## ğŸŒ Despliegue en la Nube

### OpciÃ³n 1: Railway (MÃ¡s Simple)

```bash
# 1. Instalar CLI de Railway
npm i -g @railway/cli

# 2. Iniciar proyecto
railway init

# 3. Desplegar
railway up
```

### OpciÃ³n 2: Render

1. Conectar repositorio de GitHub
2. Crear servicio Web Service
3. Configurar:
   - Build Command: `docker build -f docker/Dockerfile.api .`
   - Start Command: `python src/api/app.py`
   - Port: 8000

### OpciÃ³n 3: AWS ECS

```bash
# 1. Crear ECR repository
aws ecr create-repository --repository-name credit-risk-api

# 2. Construir y subir imagen
docker build -f docker/Dockerfile.api -t credit-risk-api .
docker tag credit-risk-api:latest <account-id>.dkr.ecr.<region>.amazonaws.com/credit-risk-api:latest
docker push <account-id>.dkr.ecr.<region>.amazonaws.com/credit-risk-api:latest

# 3. Crear task definition y service
aws ecs create-service --cluster credit-cluster --service-name credit-service --task-definition credit-task
```

### OpciÃ³n 4: Google Cloud Run

```bash
# 1. Construir imagen
docker build -f docker/Dockerfile.api -t gcr.io/<project-id>/credit-api .

# 2. Subir a Google Container Registry
docker push gcr.io/<project-id>/credit-api

# 3. Desplegar en Cloud Run
gcloud run deploy credit-api --image gcr.io/<project-id>/credit-api --platform managed
```

## ğŸ” Monitoreo y Logging

### Health Checks

```bash
# Verificar salud de la API
curl http://localhost:8000/health

# Verificar salud del Dashboard
curl http://localhost:8501/_stcore/health

# Verificar servicios Docker
docker-compose ps
```

### Logs

```bash
# Ver logs de todos los servicios
make docker-logs

# Ver logs especÃ­ficos
docker-compose logs api
docker-compose logs dashboard

# Seguir logs en tiempo real
docker-compose logs -f api

# Ver logs con timestamps
docker-compose logs --timestamps
```

### MÃ©tricas

La API expone mÃ©tricas en formato JSON:

```bash
# Obtener informaciÃ³n del modelo
curl http://localhost:8000/model/info | jq '.metrics'
```

## ğŸ› ï¸ Troubleshooting

### Problemas Comunes y Soluciones

#### 1. API no responde
```bash
# Verificar que el contenedor estÃ¡ corriendo
docker ps | grep api

# Ver logs de error
docker-compose logs api

# Reiniciar servicio
docker-compose restart api
```

#### 2. Dashboard no carga
```bash
# Verificar conexiÃ³n con API
curl http://api:8000/health

# Verificar puerto
netstat -tulpn | grep 8501

# Limpiar cache de Streamlit
rm -rf ~/.streamlit
```

#### 3. Error de conexiÃ³n a base de datos
```bash
# Verificar que PostgreSQL estÃ¡ corriendo
docker-compose ps postgres

# Probar conexiÃ³n manual
docker-compose exec postgres psql -U credit_user -d credit_db

# Reiniciar servicios dependientes
docker-compose restart api dashboard
```

#### 4. Modelo no encontrado
```bash
# Verificar que existe el archivo
ls -la models/*.pkl

# Entrenar nuevo modelo
make docker-train

# Copiar modelo manualmente
cp models/random_forest_model_*.pkl models/random_forest_model_latest.pkl
```

#### 5. Memory issues
```bash
# Limpiar cache de Docker
docker system prune -f

# Limpiar volÃºmenes no usados
docker volume prune -f

# Ver uso de recursos
docker stats
```

## ğŸ“ˆ Roadmap y Mejoras Futuras

### ğŸš€ PrÃ³ximas CaracterÃ­sticas

1. **AutenticaciÃ³n Avanzada**
   - OAuth2 con proveedores externos
   - Roles y permisos
   - Refresh tokens

2. **MÃ¡s Modelos de ML**
   - XGBoost y LightGBM
   - Deep Learning con TensorFlow
   - Ensemble methods

3. **MonitorizaciÃ³n Avanzada**
   - Prometheus + Grafana
   - Alertas automÃ¡ticas
   - Dashboard de mÃ©tricas

4. **Integraciones**
   - Webhooks para notificaciones
   - API para terceros
   - ExportaciÃ³n a BI tools

5. **Escalabilidad**
   - Kubernetes para orquestaciÃ³n
   - Auto-scaling
   - Load balancing

### ğŸ¯ Optimizaciones TÃ©cnicas

- [ ] Cache avanzado con Redis
- [ ] Async database operations
- [ ] Background jobs con Celery
- [ ] API versioning
- [ ] Rate limiting por usuario
- [ ] Circuit breakers para dependencias

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Por favor sigue estos pasos:

1. **Fork** el repositorio
2. **Crea una rama** para tu feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. **Push** a la rama (`git push origin feature/AmazingFeature`)
5. **Abre un Pull Request**

### GuÃ­as de Estilo

- **CÃ³digo**: Sigue PEP 8, usa Black para formateo
- **DocumentaciÃ³n**: Usa Google-style docstrings
- **Commits**: Mensajes descriptivos en inglÃ©s
- **Tests**: Escribe tests para nuevas funcionalidades

### Estructura de Commits

```
feat: nueva funcionalidad
fix: correcciÃ³n de bug
docs: cambios en documentaciÃ³n
style: formato, puntos y coma, etc (sin cambios funcionales)
refactor: refactorizaciÃ³n de cÃ³digo
test: aÃ±adir o corregir tests
chore: cambios en build, config, etc
```

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la **MIT License** - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- **[FastAPI](https://fastapi.tiangolo.com/)** - Para la API rÃ¡pida y moderna
- **[Streamlit](https://streamlit.io/)** - Para el dashboard interactivo
- **[Scikit-learn](https://scikit-learn.org/)** - Para los algoritmos de ML
- **[Docker](https://www.docker.com/)** - Para la containerizaciÃ³n
- **[Plotly](https://plotly.com/)** - Para las visualizaciones
- **[Pandas](https://pandas.pydata.org/)** - Para el procesamiento de datos

## ğŸ“ Soporte

Para soporte, por favor:

1. **Revisa la documentaciÃ³n** y troubleshooting guide
2. **Busca issues existentes** en GitHub
3. **Abre un nuevo issue** si no encuentras soluciÃ³n

**Contacto**: [ramirezdata22@gmail.com](mailto:ramirezdata22@gmail.com)

**Discusiones**: [GitHub Discussions](https://github.com/simon-ramirez28/credito-risk-platform/discussions)

---

<div align="center">
  
**Hecho con â¤ï¸ para la comunidad de Data Engineering**

[â­ Da una estrella en GitHub](https://github.com/simon-ramirez28/credito-risk-platform)

</div>
